---
title: "Stock data Notebook"
output:
  html_document:
    df_print: paged
---

This R Notebook provides a brief introduction of the data preprocessing and estimation for the Stock data example.

Set Directory of this folder 

```{R}

data_dir <- '/home/usuario/Documents/Barcelona_Yr1/GraphicalModels_NetworkData/LiLicode/paper_code_github_NEW/Data/STOCK/'

```

# 1. Data preprocessing
Load packages

```{R}
library(readr)
library(readxl)
library(dplyr)
library(devtools)
library(polynom)
library(ggplot2)

library(huge)
library("car")

library(tidyquant)
library(timetk)
library(data.table)

```

## Load stock data 

```{R}

setwd(data_dir)

stock_price <- read.csv('stock_prices_RAW.csv')
stock_price$date <- as.Date(stock_price$date, "%Y-%m-%d")

# install.packages('plyr')
library(plyr)## uses count from plyr not dplyr

stock_price$prccdadj_available <- 1 - is.na(stock_price$prccdadj)

stock_freq <- count(stock_price, vars = 'tic', wt_var = 'prccdadj_available') 
stock_price1 <- merge(x = stock_price, y = stock_freq, by = "tic")    ##count the freq of stocks

length(unique(stock_price$tic))
```


## Load Fama_3factor data

```{R}

setwd(data_dir)

fama_3factor <-read.csv('F-F_Research_Data_Factors_daily.CSV')
names(fama_3factor)[names(fama_3factor) == 'X'] <- 'date'
fama_3factor$rmrf <- fama_3factor$Mkt.RF - fama_3factor$RF    ## create Rm-Rf variable

## Setting Date format
str(fama_3factor$date)                                                                
fama_3factor$date <- format(as.Date(fama_3factor$date, "%Y%m%d"),"%Y-%m-%d")
str(fama_3factor$date)
fama_3factor$date <- as.Date(fama_3factor$date)
str(fama_3factor$date)

##keep the data of 2019 year
fama_3factor <- fama_3factor %>% filter(date >= "2019-01-02" & date <= "2019-12-31")  
```


## Merge Fama_3factor with stock_price2

```{R}
stock_price3 <-  merge(x = stock_price1, y = fama_3factor, by = "date")
count(stock_price3, 'tic')

## keep all stock that have 252 periods
stock_252 <- stock_price3[stock_price3$freq == 252, ]   

length(unique(stock_252$tic))
  
hist(stock_price3$freq)


```

## S&P 500 compnaies

Taken from https://web.archive.org/web/20190912150512/https://en.wikipedia.org/wiki/List_of_S%26P_500_companies dated 12/09/2019 - which was the last available

```{R}
SP500 <- read.csv('S&P500_12.09.2019.csv') 

length(unique(SP500$CIK))## 500 firms
length(unique(SP500$Symbol))## 505 stocks firms

## Merging on tic
SP500_intersect_stock_252 <- intersect(SP500$Symbol, unique(stock_252$tic))
SP500_intersect_stock_252
length(SP500_intersect_stock_252)



```

Intersecting the the S&P 500 with the data we have on trading for every day 

```{R}

stock_252_SP <- stock_252[stock_252$tic %in% SP500_intersect_stock_252,]

```


## Load risk measure data

```{R}

setwd(data_dir)

risk_index <- read.csv("10K_davisetal_dictionaries_2015-2019.txt")

length(intersect(risk_index$cik, unique(stock_252_SP$cik)))

length(intersect(risk_index$cik, unique(SP500$CIK)))

## scaling by the number of sentences 
risk_index_scaled <- risk_index
risk_index_scaled[,2:38] <- risk_index[,2:38]/risk_index[,39]
risk_index_scaled <- risk_index_scaled[,-39]
```



## Select samples 

Choose stocks that have complete risk_index (make sure E and P are not 0 vector) and also have 252 periods in stock_price252.

```{R}

## In order to be able to standerdize the network matrix, we need to make sure that neither the E nor the P vectors are 0 vectors.
nonzero_row <- risk_index_scaled[rowSums(risk_index_scaled %>% select(ends_with("_E"))) > 0 & rowSums(risk_index_scaled %>% select(ends_with("_P"))) > 0, ]
zero_row <- risk_index_scaled[rowSums(risk_index_scaled %>% select(ends_with("_E"))) == 0 | rowSums(risk_index_scaled %>% select(ends_with("_P"))) ==0, ]

length(nonzero_row$cik) + length(zero_row$cik)


stock_risk <- merge(x = stock_252_SP, y = nonzero_row, by = "cik")
length(unique(stock_risk$cik))## 3 duplicates
length(unique(stock_risk$tic))

library(dplyr)
Y <- stock_risk 



```

## Returns

```{R}

stock_return <- Y %>%
  group_by(tic) %>%
  #tq_transmute(select = PRC,
  tq_transmute(select = prccdadj,
               mutate_fun = periodReturn,
               period = 'daily',
               type = "log",
               #type = "arithmetic",
               col_rename = 'returns')


count(stock_return, 'tic')   ## 200 *252


## merge with Y, to obtain the corresponding Risk measures

daily_return <- as.data.frame(setDT(Y)[setDT(stock_return), on = c("date", "tic"),
                                       returns := returns])

daily_return <- dplyr::arrange(daily_return, tic, date)## ordered alphabetically by tic
str(daily_return)


daily_return <- daily_return %>%
  select(returns, everything())   ## move one column to the start

#Remove the first date 
daily_return <- daily_return[-which(daily_return$date=="2019-01-02"),]
```

# 2. Linear regression of log(return) on Fama-Fench

Fitting the Fama-French model for each stock 

```{R}

firms <- unique(daily_return$tic)
daily_return_residuals <- data.frame()
for(firm in firms){
  daily_return_firm <- subset(daily_return, subset=daily_return$tic == firm) 
  model1_firm <- lm((returns - RF) ~ SMB + HML + rmrf , data= daily_return_firm)
  daily_return_firm$residuals <- residuals(model1_firm)
  daily_return_firm$expected <- fitted.values(model1_firm)
  daily_return_residuals <- rbind(daily_return_residuals, daily_return_firm)
}


```

## Residual vs covariates

```{R}
par(mfrow = c(2, 2))

plot(x = daily_return_residuals$expected, y = daily_return_residuals$residuals, xlab = "fitted value", ylab = "residual")
lines(lowess(daily_return_residuals$expected, daily_return_residuals$residuals), col='red')


plot(x= daily_return_residuals$SMB, y = daily_return_residuals$residuals, xlab = "SMB", ylab = "residual")
lines(lowess(daily_return_residuals$SMB, daily_return_residuals$residuals), col='red')

plot(x= daily_return_residuals$HML, y = daily_return_residuals$residuals, xlab = "HML", ylab = "residual")
lines(lowess(daily_return_residuals$HML, daily_return_residuals$residuals), col='red')

plot(x= daily_return_residuals$rmrf, y = daily_return_residuals$residuals, xlab = "Rm-Rf", ylab = "residual")
lines(lowess(daily_return_residuals$rmrf, daily_return_residuals$residuals), col='red')

par(mfrow = c(1, 1))
```

## Residual qq-plot ##

```{R}
hist(daily_return_residuals$residuals, xlab = "residual of stock", main = "hist of stock residual", probability = TRUE)

plot(density(daily_return_residuals$residuals))


qqnorm(daily_return_residuals$residuals)
qqline(daily_return_residuals$residuals)
```

## Time series plot

```{R}
ggplot(data = daily_return_residuals,
       aes(x = date, y = returns, group = tic)) +
  geom_line(aes(col = tic)) +
  labs(x = "Date",  y = "Daily stock returns") +
  theme(legend.position = "none") +
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))

```

## Residual ACF and PACF for model1

```{R}

dataacf <- tapply(daily_return_residuals$residuals, INDEX= daily_return$tic, FUN=acf, pl=FALSE) #Obtain ACF for each stock
datapacf <- tapply(daily_return_residuals$residuals, INDEX= daily_return$tic, FUN=pacf, pl=FALSE) #Obtain PACT for each stock

r <- pr <- matrix(NA, nrow=length(dataacf), ncol=5)  #Format as matrix for easy plotting
for (i in 1:length(dataacf)) {
  r[i,] <- dataacf[[i]][[1]][2:6,,]  #start at 2, first element stores 0 order correlation
  pr[i,] <- datapacf[[i]][[1]][1:5,,]
}


#### ACF plot ####
plot(density(r[,1]), xlim=c(-0.5,1), ylim = c(0,5), main='acf_residuals', xlab='Autocorrelation', cex.axis=1.3, cex.lab=1.4)
lines(density(r[,2]), col=2)
lines(density(r[,3]), col=3)
lines(density(r[,4]), col=4)
lines(density(r[,5]), col=5)
legend('topleft', c('Order 1','Order 2','Order 3','Order 4','Order 5'), lty=1, lwd=2, col=1:5, cex=1.2)


#### PACF plot ####
plot(density(pr[,1]), xlim=c(-0.5,1), ylim = c(0,5), main='pacf_residuals', xlab='Partial autocorrelation', cex.axis=1.3, cex.lab=1.4)
lines(density(pr[,2]), col=2)
lines(density(pr[,3]), col=3)
lines(density(pr[,4]), col=4)
lines(density(pr[,5]), col=5)
legend('topleft', c('Order 1','Order 2','Order 3','Order 4','Order 5'), lty=1, lwd=2, col=1:5, cex=1.2)
```


## Put residual into a matrix

```{R}
nn <- unique(daily_return_residuals$tic)
ntic <- length(nn)
stock <- lapply(1:ntic, function(i) daily_return_residuals[daily_return_residuals$tic==nn[i], 'residuals'])
stock <- do.call(cbind, stock)
dim(stock)
```


## Monotone normalizing transform 

```{R}

stockn <- huge.npn(stock)

print(stock[1:5,1])
print(stockn[1:5,1])

```

## Density plot of tranformed stock residual

```{R}
hist(stockn, xlab = "residual of transformed stock", main = "hist of transformed stock residual", probability = TRUE)

plot(density(stockn))

qqnorm(stockn)
qqline(stockn)

hist(daily_return_residuals$residuals/sqrt(var(daily_return_residuals$residuals)), xlab = "Residuals", main = "Density", probability = TRUE, breaks = 100)


qqnorm(daily_return_residuals$residuals, main = "Normal Q-Q Plot")
#qqline(resid(model1), lwd = 3, lty = 2, col = "grey")
abline(a = 0, b = 1, lwd = 3, lty = 2, col = "grey")
```

# Network matrix

```{R}
#### take log(1+count) for each risk measure
nn1 <- unique(daily_return$tic)
nonzero_row_SP <- data.frame()
for(tic in nn1){
  nonzero_row_SP <- rbind(nonzero_row_SP, c("tic" = tic, nonzero_row[which(nonzero_row$cik == unique(daily_return$cik[which(daily_return$tic==tic)])),]))
}
mydf <- nonzero_row_SP
mydf <- arrange(mydf, tic)
upd <- unique(colnames(mydf[, 3:39]))
mydf[,names(mydf) %in% upd] <- log(mydf[,names(mydf) %in% upd] + 1)  ##add 1 to the elements of 37 risk measures and take the logarithm



#### Pearson Network: row centring
mydf_E  <- mydf %>%select(ends_with("_E"))
mydf_centering_E <- ( mydf_E - matrix(rowMeans(mydf_E), nrow = nrow( mydf_E), ncol = ncol( mydf_E), byrow = FALSE ))   ##row centering for E risks
rowMeans(mydf_centering_E)


mydf_P  <- mydf %>%select(ends_with("_P"))
mydf_centering_P <- ( mydf_P - matrix(rowMeans( mydf_P), nrow = nrow( mydf_P), ncol = ncol( mydf_P), byrow = FALSE ))   ##row centering for P risks
rowMeans(mydf_centering_P)


E_pears <- lsa::cosine(t(as.matrix(mydf_centering_E)))    ## pearson network for Economy measure
P_pears <- lsa::cosine(t(as.matrix(mydf_centering_P)))    ## pearson network for Policy measure
```

Saving the data

```{R}

#### Save data  ####

write.csv(stockn, file = paste("stock_trans_SP", ".csv", sep = ""))
write.csv(E_pears, file = paste("E_pears_SP", ".csv", sep = ""))
write.csv(P_pears, file = paste("P_pears_SP", ".csv", sep = ""))
```

