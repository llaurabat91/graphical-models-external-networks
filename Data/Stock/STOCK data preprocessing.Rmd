---
title: "Stock data Notebook"
output:
  html_document:
    df_print: paged
---

This R Notebook provides a brief introduction of the data preprocessing and estimation for the Stock data example.

Set Directory of this folder 

```{R}

data_dir <- '/home/usuario/Documents/Barcelona_Yr1/GraphicalModels_NetworkData/LiLicode/paper_code_github/'


```

# 1. Data preprocessing
Load packages

```{R}
library(readr)
library(readxl)
library(dplyr)
library(devtools)
library(polynom)
library(ggplot2)

#library(huge)
library("car")

library(tidyquant)
library(timetk)
library(data.table)

```

## Load stock data 
```{R}

setwd(data_dir)

stock_price <- read.csv('Data/Stock/Raw Data/tic_price_data.csv')           ## stock data


## Setting Date format
str(stock_price$date)
stock_price$date <- as.character(stock_price$date)          
stock_price$date <- format(as.Date(stock_price$date, "%Y%m%d"),"%Y-%m-%d")
str(stock_price$date)
stock_price$date <- as.Date(stock_price$date)
str(stock_price$date)


# install.packages('plyr')
library(plyr)

names(stock_price)[names(stock_price) == 'TICKER'] <- 'tic'
stock_freq <- count(stock_price, 'tic')                 ## 3019 stocks, not all stock have full(252) periods
stock_price1 <- merge(x = stock_price, y = stock_freq, by = "tic")    ##count the freq of stocks
```



## Load the tic data

```{R}

setwd(data_dir)

cik_ticker <- read.csv('Data/Stock/Raw Data/tic_cik_crosswalk.csv')           ## ticker-cik data

## merge ticker with stock
stock_price2 <- merge(x = stock_price1, y = cik_ticker, by = "tic")                            
```

## Load Fama_3factor data

```{R}

setwd(data_dir)

fama_3factor <-read.csv('Data/Stock/Raw Data/F-F_Research_Data_Factors_daily.CSV')
names(fama_3factor)[names(fama_3factor) == 'X'] <- 'date'
fama_3factor$rmrf <- fama_3factor$Mkt.RF - fama_3factor$RF    ## create Rm-Rf variable

## Setting Date format
str(fama_3factor$date)                                                                
fama_3factor$date <- format(as.Date(fama_3factor$date, "%Y%m%d"),"%Y-%m-%d")
str(fama_3factor$date)
fama_3factor$date <- as.Date(fama_3factor$date)
str(fama_3factor$date)

 ##keep the data of 2019 year
fama_3factor <- fama_3factor %>% filter(date >= "2019-01-02" & date <= "2019-12-31")  
```


## Merge Fama_3factor with stock_price2
```{R}
stock_price3 <-  merge(x = stock_price2, y = fama_3factor, by = "date")
count(stock_price3, 'tic')    ## 2796 stocks

## keep all stock that have 252 periods
stock_252 <- stock_price3[stock_price3$freq == 252, ]   
```


## Load risk measure data

```{R}

setwd(data_dir)

risk_index <- read.csv('Data/Stock/Raw Data/cik_cat_count_new2.csv')           ## risk metric data
risk_index <- select(risk_index, -X)
risk_tic <- merge(x = risk_index, y = cik_ticker, by = "cik")

risk_tic <- risk_tic %>%
  select(tic, everything())   ## move one column to the start


```


## Select samples 

*MAKE SURE I HAVE EVERYTHING MY MY DIAGNOSTICS RMD*

Choose stocks that have complete risk_index (make sure E and P are not 0 vector) and also have 252 periods in stock_price252.

Basically, we can just use the stock data to run regression and obtain the abnormal value, but the problem is that our risk dataset might not have the risk measure of some of the stocks, thus we need to check and choose the sample for analysis.

```{R}

## In order to be able to standerdize the network matrix, we need to make sure that neither the E nor the P vectors are 0 vectors.
nonzero_row <- risk_tic[rowSums(risk_tic %>% select(ends_with("_E"))) > 0 & rowSums(risk_tic %>% select(ends_with("_P"))) > 0, ]
zero_row <- risk_tic[rowSums(risk_tic %>% select(ends_with("_E"))) == 0 | rowSums(risk_tic %>% select(ends_with("_P"))) ==0, ]


## random choose 200 stocks in stock_252 and make sure
stock_risk <- merge(x = stock_252, y = nonzero_row, by = "tic")
count(stock_risk, 'tic')  ## 2574 stock

set.seed(1234)
library(dplyr)
Y <- stock_risk %>%
  filter(tic %in% sample(unique(tic),200))


Y$PRC <- Y$PRC*sign(Y$PRC)      ## make negative prices to be positive
```



## Log return

```{R}


# get simple return of 200 stock
stock_return <- Y %>%
  group_by(tic) %>%
  tq_transmute(select = PRC,
               mutate_fun = periodReturn,
               period = 'daily',
               type = "log",
               col_rename = 'returns')


count(stock_return, 'tic')   ## 200 *252


## merge with Y, to obtain the corrsponding Risk measures

daily_return <- as.data.frame(setDT(Y)[setDT(stock_return), on = c("date", "tic"),
                                       returns := returns])

daily_return <- dplyr::arrange(daily_return, tic, date)
str(daily_return)


daily_return <- daily_return %>%
  select(returns, everything())   ## move one column to the start
```


# 2. Linear regression of log(return) on Fama-Fench

```{R}
model1 <- lm(returns ~ SMB + HML + rmrf , data= daily_return)
summary(model1)

```



## Residual vs covariates

```{R}
par(mfrow = c(2, 2))

plot(x = fitted.values(model1), y = residuals(model1), xlab = "fitted value", ylab = "residual")
lines(lowess(fitted.values(model1), residuals(model1)), col='red')


plot(x= daily_return$SMB, y = residuals(model1), xlab = "SMB", ylab = "residual")
lines(lowess(daily_return$SMB, residuals(model1)), col='red')


plot(x= daily_return$HML, y = residuals(model1), xlab = "HML", ylab = "residual")
lines(lowess(daily_return$HML, residuals(model1)), col='red')


plot(x= daily_return$rmrf, y = residuals(model1), xlab = "Rm-Rf", ylab = "residual")
lines(lowess(daily_return$rmrf, residuals(model1)), col='red')


par(mfrow = c(1, 1))
```


## Residual qq-plot ##

```{R}
hist(resid(model1), xlab = "residual of stock", main = "hist of stock residual", probability = TRUE)

plot(density(resid(model1)))

#qqnorm(rstudent(model1))
#qqline(rstudent(model1))

qqnorm(resid(model1))
qqline(resid(model1))
```


## Time series plot

```{R}
ggplot(data = daily_return,
       aes(x = date, y = returns, group = tic)) +
  geom_line(aes(col = tic)) +
  labs(x = "Date",  y = "Daily stock returns") +
  theme(legend.position = "none") +
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))

```

## Residual ACF and PACF for model1

```{R}
daily_return$res <- residuals(model1)
dataacf <- tapply(daily_return$res, INDEX= daily_return$tic, FUN=acf, pl=FALSE)   #Obtain ACF for each stock
datapacf <- tapply(daily_return$res, INDEX= daily_return$tic, FUN=pacf, pl=FALSE) #Obtain PACT for each stock

r <- pr <- matrix(NA, nrow=length(dataacf), ncol=5)  #Format as matrix for easy plotting
for (i in 1:length(dataacf)) {
  r[i,] <- dataacf[[i]][[1]][2:6,,]  #start at 2, first element stores 0 order correlation
  pr[i,] <- datapacf[[i]][[1]][1:5,,]
}


#### ACF plot ####
plot(density(r[,1]), xlim=c(-0.5,1), ylim = c(0,5), main='acf_residuals', xlab='Autocorrelation', cex.axis=1.3, cex.lab=1.4)
lines(density(r[,2]), col=2)
lines(density(r[,3]), col=3)
lines(density(r[,4]), col=4)
lines(density(r[,5]), col=5)
legend('topleft', c('Order 1','Order 2','Order 3','Order 4','Order 5'), lty=1, lwd=2, col=1:5, cex=1.2)


#### PACF plot ####
plot(density(pr[,1]), xlim=c(-0.5,1), ylim = c(0,5), main='pacf_residuals', xlab='Partial autocorrelation', cex.axis=1.3, cex.lab=1.4)
lines(density(pr[,2]), col=2)
lines(density(pr[,3]), col=3)
lines(density(pr[,4]), col=4)
lines(density(pr[,5]), col=5)
legend('topleft', c('Order 1','Order 2','Order 3','Order 4','Order 5'), lty=1, lwd=2, col=1:5, cex=1.2)
```



## Put residual into a matrix

```{R}
nn <- unique(daily_return$tic)
ntic <- length(nn)
stock <- lapply(1:ntic, function(i) daily_return[daily_return$tic==nn[i], 'res'])
stock <- do.call(cbind, stock)
dim(stock)     #check: 200 tic, 252 observations
```

## detect the outliers

```{R}

qqPlot(model1, labels=tic(daily_return), id.method="identify",
       simulate=TRUE, main="Q-Q Plot")


#stock[107, 31]   ## nn[31] "CAPR"
#stock[111, 101]  ## nn[101] "HSON"


outlier <- daily_return %>% filter(tic == "CAPR" | tic == 'HSON')
outlier1 <- daily_return %>% filter(tic == "CAPR")
outlier2 <- daily_return %>% filter(tic == "HSON")


## time series plot ##

daily_return$date2 <- as.Date(daily_return$date)

ggplot(data = daily_return,
       aes(x = date2, y = returns, group = tic)) +
  geom_line(aes(col = tic)) +
  labs(x = "Date",  y = "Daily stock returns") +
  theme(legend.position = "none") +
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))
```


## Monotone normalizing transform 

```{R}

stockn <- huge.npn(stock)

print(stock[1:5,1])
print(stockn[1:5,1])

```


## Density plot of tranformed stock residual

```{R}
hist(stockn, xlab = "residual of transformed stock", main = "hist of transformed stock residual", probability = TRUE)

plot(density(stockn))

qqnorm(stockn)
qqline(stockn)

hist(resid(model1)/sigma(model1), xlab = "Residuals", main = "Density", probability = TRUE, breaks = 100)


qqnorm(resid(model1), main = "Normal Q-Q Plot")
#qqline(resid(model1), lwd = 3, lty = 2, col = "grey")
abline(a = 0, b = 1, lwd = 3, lty = 2, col = "grey")
```



# Network matrix

```{R}
#### take log(1+count) for each risk measure
nn1 <- unique(daily_return$tic)
mydf <- nonzero_row[nonzero_row$tic%in%nn1, ]
mydf <- arrange(mydf, tic)
upd <- unique(colnames(mydf[, 3:39]))
mydf[,names(mydf) %in% upd] <- log(mydf[,names(mydf) %in% upd] + 1)  ##add 1 to the elements of 37 risk measures and take the logarithm



#### Pearson Network: row centring
mydf_E  <- mydf %>%select(ends_with("_E"))
mydf_centering_E <- ( mydf_E - matrix(rowMeans(mydf_E), nrow = nrow( mydf_E), ncol = ncol( mydf_E), byrow = FALSE ))   ##row centering for E risks
rowMeans(mydf_centering_E)


mydf_P  <- mydf %>%select(ends_with("_P"))
mydf_centering_P <- ( mydf_P - matrix(rowMeans( mydf_P), nrow = nrow( mydf_P), ncol = ncol( mydf_P), byrow = FALSE ))   ##row centering for P risks
rowMeans(mydf_centering_P)


E_pears <- lsa::cosine(t(as.matrix(mydf_centering_E)))    ## pearson network for Economy measure
P_pears <- lsa::cosine(t(as.matrix(mydf_centering_P)))    ## pearson network for Policy measure
```

Saving the data

```{R}

#### Save data  ####
# write.csv(stock, file = paste("stock_27Jun", ".csv", sep = ""))
# write.csv(stockn, file = paste("stock_trans", ".csv", sep = ""))
# write.csv(E_pears, file = paste("E_pears", ".csv", sep = ""))
# write.csv(P_pears, file = paste("P_pears", ".csv", sep = ""))
```
