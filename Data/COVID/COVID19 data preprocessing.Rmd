---
title: "COVID19 Notebook"
output:
  html_document:
    df_print: paged
---

This R Notebook provides a brief introduction of the data preprocessing and estimation for the COVID19 example.

Set Directory of this folder 

```{R}

data_dir <- '/home/usuario/Documents/Barcelona_Yr1/GraphicalModels_NetworkData/LiLicode/paper_code_github/'


```

#  Data preprocessing
Load packages

```{R}
library(readxl)
library(readr)
library(reshape)
library(tidyverse)
library(geosphere)
library(dplyr)
library(data.table)
library(tidyquant)
library(plm)
#library(maditr)

library("mgcv")

library(stargazer)
```

## Load the data

### Population data

Load the county-level population data of US in 2019, which was obtained from the U.S. Census Bureau: [ co-est2019-annres.xlsx](https://www2.census.gov/programs-surveys/popest/tables/2010-2019/counties/totals/).

```{R}
setwd(data_dir)

county_pop <- read_excel('Data/COVID/Raw Data/2019 Population.xlsx')
county_pop <- data.frame(gsub("\\.", "", county_pop$name), county_pop$`2019`)    ## remove all . in name
names(county_pop)[1:2] <- c("County", "Population")
```


### FIPS code data

To allow for a better match between datasets, we also extracted "FIPS code" that uniquely identifies counties within the USA from the U.S.Bureau of Labor Statistics [FIPS data](https://www.bls.gov/cew/classifications/areas/sic-area-titles.htm).

```{R}
setwd(data_dir)

my_FIPS <- read_csv('Data/COVID/Raw Data/FIPS code.csv')
my_FIPS <- data.frame(gsub("\\.", "", my_FIPS$name), my_FIPS$code)
names(my_FIPS)[1:2] <- c("County", "FIPS")
```

Merge the population data with FIPS code data and select top100 counties.

```{R}
county_FIPS <- merge(x = county_pop, y = my_FIPS, by = "County")    
county_FIPS <- arrange(county_FIPS, -Population)
county_FIPS <- tibble::rowid_to_column(county_FIPS, "ID")                        ## add ID
county_FIPS$FIPSnew <-str_pad(county_FIPS$FIPS, 5, pad = "0")                    ## Add leading 0's to FIPS to match the Facebook data that follows.
county_top100 <- subset(county_FIPS, ID <= 100)                                  ## select top100 counties
county_top100spilt<- cbind.data.frame(county_top100$ID, county_top100$County,
                                      county_top100$Population, county_top100$FIPS, 
                                      county_top100$FIPSnew, 
                                      str_split_fixed(county_top100$County, ", ", 2))   ## split column2, to better merge with vaccination data
names(county_top100spilt) <- c("ID", "County", "Population", "FIPS","FIPSnew", "County1", "State")
```

###  Facebook connectivity data
This data use an anonymized snapshot of all active Facebook users and their friendship networks to measure the intensity of connectedness between locations, represented by Social Connectedness Index (SCI). Specifically, it measures the relative probability that two individuals across two locations are friends with each other on Facebook [Facebook connectivity](https://data.humdata.org/dataset/social-connectedness-index). 

Load the data and select top100 counties

```{R}
setwd(data_dir)

my_facebook <- read_tsv('Data/COVID/Raw Data/SCI data.tsv')

my_facebook$FIPSnew <-my_facebook$user_loc  
my_facebook1 <- merge(x=my_facebook, y = county_FIPS, by = "FIPSnew")    ## merge with county_FIPS, easy to expand the sample size
my_facebook1 <- arrange(my_facebook1, -Population)
my_facebook2 <- my_facebook1[ which( my_facebook1$ID <= 100), ]          ## select top100 by ID

county_FIPS$fr_loc <- county_FIPS$FIPSnew
my_facebook3 <- merge(x=my_facebook2, y = county_FIPS, by = "fr_loc")
my_facebook3 <- arrange(my_facebook3, -Population.y)
my_facebook4 <- my_facebook3[ which( my_facebook3$ID.y <= 100), ]        ## select top100 by ID

my_facebook_final <- select(my_facebook4, -Population.x, -Population.y,  -FIPS.x, -FIPS.y, -FIPSnew.y)
my_facebook_final$ID.x <- as.character(my_facebook_final$ID.x)
my_facebook_final$ID.y <- as.character(my_facebook_final$ID.y)
```

Delect ID = 94

```{R}
my_facebook_final2 <- my_facebook_final[!(my_facebook_final$ID.x=="94"| my_facebook_final$ID.y=="94"), ]   ## ID=94 (District of Columbia) is missing in Policy Variable, so delete it now
```

Reshape wide-format data and melts it into long-format data

```{R}
my_facebook_final3 <- reshape2::melt(my_facebook_final2)  ##takes wide-format data and melts it into long-format data.
my_facebook_final3$ID.x <- as.numeric(my_facebook_final3$ID.x)
my_facebook_final3$ID.y <- as.numeric(my_facebook_final3$ID.y)
my_facebook_final3 <- arrange(my_facebook_final3, ID.x)
```

#### Generate Facebook connectivity network

```{R}
#SCI_index <- maditr::dcast(my_facebook_final3, ID.x ~ ID.y)        ## transform into network matrix
SCI_index <- reshape2::dcast(my_facebook_final3, ID.x ~ ID.y) 
SCI_index <- select(SCI_index, -ID.x)
class(SCI_index)
```

### Population density data
The population density were obtained by dividing population by the area of the region. Area data were obtained from U.S. Census Bureau [Area data](https://tigerweb.geo.census.gov/tigerwebmain/TIGERweb_main.html).

```{R}
setwd(data_dir)

my_area <- read_excel('Data/COVID/Raw Data/US County Area.xlsx')

names(my_area)[1] <- "FIPS"
my_area <- select(my_area, FIPS, NAME, AREALAND)
```

Merge population data with area data and generate log(population density)

```{R}
pop_densi <- merge(x = county_top100spilt, y = my_area, by = "FIPS") 
pop_densi <- arrange(pop_densi, ID)

pop_densi$density_sk <- pop_densi$Population/ (pop_densi$AREALAND *1000000)      ## population per square kilometers
pop_densi$log_popdensi_sk <- log(pop_densi$density_sk)        ## log population density
pop_densi <- select(pop_densi, -ID, -County, -Population,
                    -County1, -FIPSnew, -State, -NAME, -AREALAND)
```

###  COVID19 confirmed data
Load the time series table of US confirmed cases reported at the county level for the period 1/22/2020-11/30/2021 [time$\_$series$\_$covid19$\_$confirmed$\_$US.csv](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv). Note that it is cumulative data.


```{R}
covid_data <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv"
my_covid_data<-read_csv(url(covid_data))

confirmed_US <- merge(x = county_top100spilt, y = my_covid_data, by = "FIPS")    ## merge to obtain top100 samples
confirmed_US <- select(confirmed_US, -UID,
                       -iso2, -iso3, -code3, -Admin2,
                       -Country_Region, -Combined_Key, -Province_State)          ## keep variables that of importance
head(confirmed_US)

confirmed_US1 <- confirmed_US[, c(1:688)]                                        ## delete columns after 2021-11-30
confirmed_pop <- merge(x = confirmed_US1, y = pop_densi, by = "FIPS")
head(confirmed_pop)
confirmed_pop <- arrange(confirmed_pop, ID)
```


#### Generate Geographical distance Network

```{R}
coordinate <- cbind(confirmed_pop$Long_, confirmed_pop$Lat)      
coordinate <- coordinate[-94,]                                                   ## drop ID = 94, because ID = 94 is missing in Policy variable
Geodist <- distm(coordinate, coordinate, fun = distHaversine)                    ## assumes a spherical earth, ignoring ellipsoidal effects
```

Due to the lack of temperature data for ID = 65 (San Francisco county), find the geographically closest one.

```{R}
#### ID = 65 is missing in Temperature, find the closest county to replace
which(apply(Geodist, 1, function(x) any(x %in% min(Geodist[65, ][which(Geodist[65, ]>0)]))))    ## ID = 85 is the closest(San Mateo County, California) to ID = 65
```

Reshape wide-format data and melts it into long-format

```{R}
confirmed_pop_Long <- melt(confirmed_pop, 
                           id.vars = c( "FIPS", "ID", "County", "Population",
                                        "FIPSnew", "County1", "State",  "Lat",
                                        "Long_", "density_sk", "log_popdensi_sk"),
                           variable.name = "date")
names(confirmed_pop_Long)[12:13] <- c("Date", "cum_Confirmed")


str(confirmed_pop_Long$Date)                                                                  ## set date format
confirmed_pop_Long$Date <-format(as.Date(confirmed_pop_Long$Date, '%m/%d/%y'),"%Y-%m-%d")
confirmed_pop_Long$Date <- as.Date(confirmed_pop_Long$Date)
str(confirmed_pop_Long$Date)
```

Plot the ggplot of cumulative COVID19 data

```{R}
ggplot(data = confirmed_pop_Long, 
       aes(x = Date, y = cum_Confirmed , group = County)) +
  geom_line(aes(col = County)) +
  labs(x = "Date",  y = "Daily Cumulative Confirmed Case") +
  theme(legend.position = "none") + 
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))                             ## The Plot of Daily Cumulative Data
```

Convert COVID19 data into daily data

```{R}
confirmed_pop_Long2 <- confirmed_pop_Long %>%
  group_by(County)%>%
  arrange(ID, Date) %>%
  mutate(daily_confirmed = c(first(cum_Confirmed), diff(cum_Confirmed)))         ## convert to daily data  (have negative value)
```

Plot the ggplot of COVID19 daily data

```{R}
ggplot(data = confirmed_pop_Long2, 
       aes(x = Date, y = daily_confirmed, group = County)) +
  geom_line(aes(col = County)) +
  labs(x = "Date",  y = "daily_confirmed") +
  theme(legend.position = "none") + 
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))                             ## The plot of Daily Confirmed Data
```

Generate  per 10,000 daily confirmed data

```{R}
confirmed_pop_Long2$per10000_daily_confirmed <- (confirmed_pop_Long2$daily_confirmed / confirmed_pop_Long2$Population ) * 10000   ## per 10,000 daily confirmed case
```


Plot per10000 daily COVID19 confirmed data

```{R}
ggplot(data = confirmed_pop_Long2, 
       aes(x = Date, y = per10000_daily_confirmed, group = County)) +
  geom_line(aes(col = County)) +
  labs(x = "Date",  y = "per 10000 daily_confirmed") +
  theme(legend.position = "none") + 
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))                ## The plot of per10000 daily confirmed data
```


### Vaccination Data  

Load state-level vaccination data for the period 12/14/2020 - 11/23/2021[vaccination data](https://github.com/govex/COVID-19/tree/master/data_tables/vaccine_data/us_data/time_series). Note that it is cumulative data.

```{R}

Vaccinated <- "https://raw.githubusercontent.com/govex/COVID-19/master/data_tables/vaccine_data/us_data/time_series/time_series_covid19_vaccine_doses_admin_US.csv"
my_Vaccinated <-read_csv(url(Vaccinated))
my_Vaccinated <- select(my_Vaccinated, -FIPS, -UID,
                        -iso2, -iso3, -code3, -Admin2,
                        -Country_Region, -Lat, -Long_, -Combined_Key, -Population)

names(my_Vaccinated)[1] <- "State"
vaccinated <- merge(x = county_top100spilt, y = my_Vaccinated, by = "State")
vaccinated1 <- vaccinated[, c(1:359)] 
vaccinated1 <- arrange(vaccinated1, ID)
head(vaccinated1)
```

Reshape wide-format data and melts it into long-format

```{R}
vaccinated_Long <- melt(vaccinated1,
                        id.vars = c( "State", "ID",  "County", "Population",
                                     "FIPS", "County1", "FIPSnew"), 
                        variable.name = "date")                                   ## wide format to long format  

names(vaccinated_Long)[8:9] <- c("Date", "cum_Vaccinated")


str(vaccinated_Long$Date)
vaccinated_Long$Date <- as.Date(vaccinated_Long$Date)
str(vaccinated_Long$Date)
```

Plot the Cumulative Vaccination

```{R}
ggplot(data = vaccinated_Long, 
       aes(x = Date, y = cum_Vaccinated , group = State)) +
  geom_line(aes(col = State)) +
  labs(x = "Date",  y = "cum_Vaccinated Case") +
  theme(legend.position = "none") +
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))                             ## The Plot of Daily Cumulative Vaccination
```

Diagnosis the warning messiage

```{R}
sum(is.na(vaccinated_Long))         ## diagnosis the warning messiage
colSums(is.na(vaccinated_Long))     ## all NAs are in coloum "cum_Vaccinated"
```

Convert to daily vaccinated data

```{R}
vaccinated_Long2 <- vaccinated_Long %>%
  group_by(County)%>%
  arrange(ID, Date) %>%
  mutate(daily_vaccinated = c(first(cum_Vaccinated), diff(cum_Vaccinated)))      ## convert to daily vaccinated data
```

Plot daily vaccination data

```{R}
ggplot(data = vaccinated_Long2, 
       aes(x = Date, y = daily_vaccinated, group = State)) +
  geom_line(aes(col = State)) +
  labs(x = "Date",  y = "daily_vaccinated") +
  theme(legend.position = "none") +
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))                             ## The plot of daily vaccinated data
```


Diagnosis the warning message

```{R}
sum(is.na(vaccinated_Long2))           ## diagnosis the warning message
colSums(is.na(vaccinated_Long2))      ## total number of NA values per column
```

Generate per daily vaccinated data

```{R}
vaccinated_Long2$per_daily_vaccinated <- (vaccinated_Long2$daily_vaccinated / vaccinated_Long2$Population)  ## per daily vaccinated data
```

Plot per daily vaccination 

```{R}
ggplot(data = vaccinated_Long2, 
       aes(x = Date, y = per_daily_vaccinated, group = State)) +
  geom_line(aes(col = State)) +
  labs(x = "Date",  y = "per_daily_vaccinated") +
  theme(legend.position = "none") +
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))                             ## The plot of Per Daily Vaccination
```

Merge with the above data

```{R}
confirmed_pop_vacc <- left_join(confirmed_pop_Long2, vaccinated_Long2)
```

### Policy data

The Oxford Covid-19 Government Response Tracker (GitHub repo, university website) tracks individual policy measures across 20 indicators. They also calculate several indices to give an overall impression of government activity. Here we use Containment and health index as the proxy of Policy variable [Policy data](https://github.com/CSSEGISandData/COVID-19_Unified-Dataset)


```{R}
my_policy <- "https://raw.githubusercontent.com/OxCGRT/USA-covid-policy/master/data/OxCGRT_US_latest.csv"
my_policy <-read_csv(url(my_policy))
```

Keep the variables that of importance

```{R}
policy <- my_policy%>% filter_all(any_vars(str_detect(str_to_lower(.), "^state_wide")))  ## keep all US data
str(policy)
policy2 <- select(policy, 
                  RegionName, Date,
                  `C1_School closing`, C1_Flag, 
                  `C2_Workplace closing`, C2_Flag, 
                  `C3_Cancel public events`, C3_Flag, 
                  `C4_Restrictions on gatherings`, C4_Flag,
                  `C5_Close public transport`, C5_Flag, 
                  `C6_Stay at home requirements`, C6_Flag, 
                  `C7_Restrictions on internal movement`, C7_Flag, 
                  `C8_International travel controls`,
                  `H1_Public information campaigns`, H1_Flag,
                  `H2_Testing policy`,
                  `H3_Contact tracing`,
                  `H6_Facial Coverings`, H6_Flag,
                  `H7_Vaccination policy`, H7_Flag,
                  `H8_Protection of elderly people`, H8_Flag,
                  ContainmentHealthIndex
                  )             ## keep variables that of importance

policy3 <- policy2 %>% filter(Date >= "20200122" & Date <= "20211130")
names(policy3)[1:27] <- c("State", "Date", "C1","C1_Flag", "C2", "C2_Flag", "C3", "C3_Flag", 
                          "C4", "C4_Flag","C5", "C5_Flag", "C6", "C6_Flag",
                          "C7", "C7_Flag", "C8",
                          "H1", "H1_Flag", "H2", "H3", "H6", "H6_Flag", 
                          "H7", "H7_Flag", "H8", "H8_Flag")      ##  Make the name more concise


str(policy3$Date)                                                                ## Setting Date format
policy3$Date <- as.character(policy3$Date)
policy3$Date <- format(as.Date(policy3$Date, "%Y%m%d"),"%Y-%m-%d")
str(policy3$Date)
policy3$Date <- as.Date(policy3$Date) 
str(policy3$Date)


colSums(is.na(policy3))                                     ## Contain many NAs
```


Now, We need to Interpolate for the variable 'Containment Health Index'. The methodology for calculating Indices is here: [Indices](https://github.com/OxCGRT/covid-policy-tracker/blob/master/documentation/index_methodology.md)

(1) Firstly, save data and Interpolate C1-H8 in Excel, which is easier. Here we use before-and-after averaging to interpolate missing values in C1-H8.
```{R}
write.csv(policy3, file = paste("policy3", ".csv", sep = "")) 
```
 
(2) Import the Interpolated data file "inter-policy.csv"

```{R}
Interpolation_policy <- read_csv('./Pre-processed Data/inter-policy.csv')
Interpolation_policy <- Interpolation_policy[, -1]

names(Interpolation_policy)[2] <- "Date"
str(Interpolation_policy$Date) 
Interpolation_policy$Date <- as.Date(Interpolation_policy$Date)
str(Interpolation_policy$Date)
```

(3) Interpolate all 'Flag' variables, replace all NA to 0

```{R}
selected_columns <- grep("_Flag", names(Interpolation_policy))

Interpolation_policy <- Interpolation_policy %>% 
  mutate(across(all_of(selected_columns), ~replace_na(.x, 0)))
```

(4) Calculate $I_{jt}$ Indices

```{R}
Interpolation_policy$Ic1 <- ifelse(Interpolation_policy$C1 ==0, 0, 100 *(Interpolation_policy$C1- 0.5*(1-Interpolation_policy$C1_Flag))/3)
Interpolation_policy$Ic2 <- ifelse(Interpolation_policy$C2 ==0, 0, 100 *(Interpolation_policy$C2- 0.5*(1-Interpolation_policy$C2_Flag))/3)
Interpolation_policy$Ic3 <- ifelse(Interpolation_policy$C3 ==0, 0, 100 *(Interpolation_policy$C3- 0.5*(1-Interpolation_policy$C3_Flag))/2)
Interpolation_policy$Ic4 <- ifelse(Interpolation_policy$C4 ==0, 0, 100 *(Interpolation_policy$C4- 0.5*(1-Interpolation_policy$C4_Flag))/4)
Interpolation_policy$Ic5 <- ifelse(Interpolation_policy$C5 ==0, 0, 100 *(Interpolation_policy$C5- 0.5*(1-Interpolation_policy$C5_Flag))/2)
Interpolation_policy$Ic6 <- ifelse(Interpolation_policy$C6 ==0, 0, 100 *(Interpolation_policy$C6- 0.5*(1-Interpolation_policy$C6_Flag))/3)
Interpolation_policy$Ic7 <- ifelse(Interpolation_policy$C7 ==0, 0, 100 *(Interpolation_policy$C7- 0.5*(1-Interpolation_policy$C7_Flag))/2)
Interpolation_policy$Ic8 <- ifelse(Interpolation_policy$C8 ==0, 0, 100 *(Interpolation_policy$C8)/4)

Interpolation_policy$Ih1 <- ifelse(Interpolation_policy$H1 ==0, 0, 100 *(Interpolation_policy$H1- 0.5*(1-Interpolation_policy$H1_Flag))/2)
Interpolation_policy$Ih2 <- ifelse(Interpolation_policy$H2 ==0, 0, 100 *(Interpolation_policy$H2)/3)
Interpolation_policy$Ih3 <- ifelse(Interpolation_policy$H3 ==0, 0, 100 *(Interpolation_policy$H3)/2)

Interpolation_policy$Ih6 <- ifelse(Interpolation_policy$H6 ==0, 0, 100 *(Interpolation_policy$H6- 0.5*(1-Interpolation_policy$H6_Flag))/4)
Interpolation_policy$Ih7 <- ifelse(Interpolation_policy$H7 ==0, 0, 100 *(Interpolation_policy$H7- 0.5*(1-Interpolation_policy$H7_Flag))/5)
Interpolation_policy$Ih8 <- ifelse(Interpolation_policy$H8 ==0, 0, 100 *(Interpolation_policy$H8- 0.5*(1-Interpolation_policy$H8_Flag))/3)
```

(5) Interpolate 'Containment Health Index' using Simple Mean of Ic1 ~ Ih8

```{R}
Interpolation_policy$ContainmentHealthIndex1 <- ifelse(is.na(Interpolation_policy$ContainmentHealthIndex), rowMeans(Interpolation_policy[,29:42]), Interpolation_policy$ContainmentHealthIndex)
colSums(is.na(Interpolation_policy)) 


Interpolation_policy <- select(Interpolation_policy,
                               State, Date,
                               ContainmentHealthIndex, ContainmentHealthIndex1)

confirm_pop_vacc_policy <- left_join(confirmed_pop_vacc, Interpolation_policy)    ## merge with previous data

colSums(is.na(confirm_pop_vacc_policy))                                           
unique(confirm_pop_vacc_policy[which(is.na(confirm_pop_vacc_policy$ContainmentHealthIndex1)),2:3])   ## ID =94(District of Columbia) is missing in policy
```

### Temperature data
Extract the daily average near-surface air temperature (T) from the Hydromet folder [Temperature data](https://github.com/CSSEGISandData/COVID-19_Unified-Dataset/tree/master/Hydromet)


```{R}
Temp <- list()    ## read T into a list

for (i in seq(1, 12)){
  data_path6 <- paste0(data_dir,"Data/COVID/Raw Data/Hydromet/Hydromet_2020", i, ".rds")
  data <-  readRDS(file = data_path6) 
  Temp_df<- as.data.frame(data)
  Temp[[i]]<-Temp_df
}


for (i in seq(1, 11)){
  data_path6 <- paste0(data_dir,"Data/COVID/Raw Data/Hydromet/Hydromet_2021", i, ".rds")
  data <-  readRDS(file = data_path6) 
  Temp_df<- as.data.frame(data)
  Temp[[i+12]]<-Temp_df
}
```

Select 4 columns ("ID", "Date", "T", and "HydrometSource"). keep Temperature if HydrometSource == "ERA5". HydrometSource == "ERA5-CIESIN" is population weighted temperature.

```{R}
func <- function(z){
  z<- filter(z, HydrometSource == "ERA5")                     
  z<- select(z, 1:3, 28)
  z<- z%>% filter_all(any_vars(str_detect(str_to_lower(.), "^us")))
  
  z <-z %>%
    separate(ID, 
             into = c("country", "FIPSnew"), 
             sep = "(?<=[A-Za-z])(?=[0-9])",
             fill = "right"
    )
  z <- merge(x = county_top100spilt, y = z, by = "FIPSnew")  
  
  return(z)
}

Temperature <- lapply(Temp, func)                                                
temperature <- do.call(rbind.data.frame, Temperature)               ## merge (99 county, ID=65 San Francisco is missing)
temperature <- temperature %>% arrange(ID, Date) %>% filter(Date >= "2020-01-22")


class(temperature)
setDT(temperature) 
class(temperature)
```


Temperature of ID=85 is  missing. Use ID=65 to replace

```{R}
temperature2 <- rbind(temperature, copy(temperature[ID == 85])[, FIPSnew:= "06075"][,ID:= 65]
                      [, County:= "San Francisco County, California"][, Population:= 881549]
                      [, FIPS:=6075][, County1:="San Francisco County"])           

head(temperature2[ID== 65])
head(temperature2[ID== 85])
```

Merge with the above data

```{R}
confirm_pop_vacc_policy_tem <- left_join(confirm_pop_vacc_policy, temperature2)  

colSums(is.na(confirm_pop_vacc_policy_tem)) 
confirm_pop_vacc_policy_tem1 <- confirm_pop_vacc_policy_tem[confirm_pop_vacc_policy_tem$ID != 94, ]   ## delete if ID = 94
colSums(is.na(confirm_pop_vacc_policy_tem1)) 
```

### Final data: COVID19 martality (daily level)

```{R}
myfinal_daily <-confirm_pop_vacc_policy_tem1   
 
# replace negative values by 0
sum(myfinal_daily$per10000_daily_confirmed < 0) 
myfinal_daily$per10000_daily_confirmed <- ifelse(myfinal_daily$per10000_daily_confirmed < 0, 0, myfinal_daily$per10000_daily_confirmed)
sum(myfinal_daily$per10000_daily_confirmed < 0)
 
# replace negative values by 0
sum(myfinal_daily$per_daily_vaccinated < 0, na.rm= TRUE)        
myfinal_daily$per_daily_vaccinated <- ifelse(myfinal_daily$per_daily_vaccinated < 0, 0, myfinal_daily$per_daily_vaccinated)
sum(myfinal_daily$per_daily_vaccinated < 0, na.rm = TRUE)
myfinal_daily$per_daily_vaccinated[is.na(myfinal_daily$per_daily_vaccinated)] <- 0

colSums(is.na(myfinal_daily))
```

Convert daily data to weekly data

```{R}
str(myfinal_daily)
col_order <- c("ID", "Date", "FIPS","County", "Population", "log_popdensi_sk",
             "per10000_daily_confirmed",  "per_daily_vaccinated", "T",
               "ContainmentHealthIndex1")

myfinal_daily1 <- myfinal_daily[, col_order]

## from FIPS to ContainmentHealthIndex1, break to Mean of weekly data
myfinal_weekly <- myfinal_daily1 %>%
  group_by(ID, County) %>%
  arrange(ID, Date) %>%
  tq_transmute(select     = FIPS:ContainmentHealthIndex1,
               mutate_fun = apply.weekly,
               FUN        =  mean)            

## generate weekly data
myfinal_weekly$weekly_confirmed <- (myfinal_weekly$per10000_daily_confirmed )* 7   
myfinal_weekly$weekly_vaccinated <- (myfinal_weekly$per_daily_vaccinated)* 7


## generate cumulative vaccination
myfinal_weekly <-  myfinal_weekly %>% 
  group_by(ID) %>% 
  arrange(ID, Date)%>%
  mutate(weekly_cum_vaccinated = cumsum(weekly_vaccinated))         
```

Plot the weekly confirmed COVID data

```{R}

ggplot(data = myfinal_weekly, 
       aes(x = Date, y = weekly_confirmed, group = County)) +
  geom_line(aes(col = County)) +
  labs(x = "date",  y = "per_week_confirmed") +
  theme(legend.position = "none") +
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))                              ## The Plot of Weekly Confirmed 
```

Plot the Cumulative Weekly Vaccinated data

```{R}
ggplot(data = myfinal_weekly, 
       aes(x = Date, y = weekly_cum_vaccinated, group = County)) +
  geom_line(aes(col = County)) +
  labs(x = "date",  y = "sum_per_vaccinated") +
  theme(legend.position = "none") +
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1))                               ## The Plot of Cumulative Weekly Vaccinated
```


Standardise all data

```{R}
st_myfinal_weekly <- myfinal_weekly %>% 
  ungroup() %>% 
  mutate_at(c("log_popdensi_sk", "ContainmentHealthIndex1", "T",
              "weekly_confirmed", "weekly_cum_vaccinated"), 
            ~(scale(.) %>% as.vector), na.rm = TRUE)                            ## standardise 
```

# Regression Analysis

Histogram of the COVID data

```{R}
options(scipen=4)
theme_set(theme_bw())
hist(st_myfinal_weekly$weekly_confirmed, 
     xlab = "Per10000 population weekly Confirmed Case (Standardized) ",
     main = "Hist of Per10000 Weekly_Confirmed Case ")
```


Plot the weekly confirmed COVID data 
 
```{R}
ggplot(data = st_myfinal_weekly, 
       aes(x = Date, y = weekly_confirmed, group = County)) +
  geom_line(aes(col = County)) +
  labs(x = "date",  y = "Per 10000 weekly Confirmed Case (standerdized)") +
  theme(legend.position = "none") +  
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x=element_text(angle=60, hjust=1)) 
```

Create the log of weekly confirmed data

```{R}
st_myfinal_weekly$log_weekly_confirmed <- log(1+ st_myfinal_weekly$weekly_confirmed) 
```

Create lag variable mamually

```{R}
mydf <- data.frame(st_myfinal_weekly)
mydf$log_weekly_confirmedlag1 <- c(NA, mydf$log_weekly_confirmed[-nrow(mydf)])

#THE CODE BELOW SETS THAT FIRST VALUE TO NA
nn <- unique(mydf$County)
for (i in 1:length(nn)) {
  sel= which(mydf$County == nn[i])
  mydf[sel[1], 'log_weekly_confirmedlag1']= NA
}

head(mydf)
mydf <- mydf[rowSums(is.na(mydf)) == 0, ]  #select rows with no missing values (i.e. excludes the first entry of each county)
```

### Model1: regression analysis without AR1 term

```{R}

fe_model1 <- gam(log_weekly_confirmed ~ log_popdensi_sk + s(T)  + 
                   weekly_cum_vaccinated + ContainmentHealthIndex1 + factor(Date),
                 data = mydf)

summary(fe_model1)
```

Residual ACF and PACF for model without AR terms

```{R}
mydf$res <- residuals(fe_model1)

dataacf <- tapply(mydf$res, INDEX= mydf$County, FUN=acf, pl=FALSE)   #Obtain ACF for each county
datapacf <- tapply(mydf$res, INDEX= mydf$County, FUN=pacf, pl=FALSE) #Obtain PACT for each county

r <- pr <- matrix(NA, nrow=length(dataacf), ncol=5)  #Format as matrix for easy plotting
for (i in 1:length(dataacf)) {
  r[i,] <- dataacf[[i]][[1]][2:6,,]  #start at 2, first element stores 0 order correlation
  pr[i,] <- datapacf[[i]][[1]][1:5,,]
}

plot(density(r[,1]), xlim=c(-0.5,1), ylim = c(0,5), main='acf_residuals', xlab='Autocorrelation', cex.axis=1.3, cex.lab=1.4)
lines(density(r[,2]), col=2)
lines(density(r[,3]), col=3)
lines(density(r[,4]), col=4)
lines(density(r[,5]), col=5)
legend('topleft', c('Order 1','Order 2','Order 3','Order 4','Order 5'), lty=1, lwd=2, col=1:5, cex=1.2)


plot(density(pr[,1]), xlim=c(-0.5,1), ylim = c(0,5), main='pacf_residuals', xlab='Partial autocorrelation', cex.axis=1.3, cex.lab=1.4)
lines(density(pr[,2]), col=2)
lines(density(pr[,3]), col=3)
lines(density(pr[,4]), col=4)
lines(density(pr[,5]), col=5)
legend('topleft', c('Order 1','Order 2','Order 3','Order 4','Order 5'), lty=1, lwd=2, col=1:5, cex=1.2)
```

### Model 2: regression analysis with AR1 term

```{R}
fe_model2 <- gam(log_weekly_confirmed ~ log_weekly_confirmedlag1 +
                   log_popdensi_sk + s(T)  + weekly_cum_vaccinated +
                   ContainmentHealthIndex1 + factor(Date), 
                 data = mydf)

summary(fe_model2)
stargazer(fe_model2, omit = c("date", "T"), type="text",title="Model With AR1 Term")
```


Residual ACF and PACF for model with AR1 term
 
```{R}
mydf$res <- residuals(fe_model2)

dataacf <- tapply(mydf$res, INDEX= mydf$County, FUN=acf, pl=FALSE)   #Obtain ACF for each county
datapacf <- tapply(mydf$res, INDEX= mydf$County, FUN=pacf, pl=FALSE) #Obtain PACT for each county

r <- pr <- matrix(NA, nrow=length(dataacf), ncol=5)  #Format as matrix for easy plotting
for (i in 1:length(dataacf)) {
  r[i,] <- dataacf[[i]][[1]][2:6,,]  #start at 2, first element stores 0 order correlation
  pr[i,] <- datapacf[[i]][[1]][1:5,,]
}



plot(density(r[,1]), xlim=c(-0.5,1), ylim=c(0,5),  xlab='Autocorrelation', cex.axis=1.3, cex.lab=1.4, main = "acf_residuals_AR1")
lines(density(r[,2]), col=2)
lines(density(r[,3]), col=3)
lines(density(r[,4]), col=4)
lines(density(r[,5]), col=5)
legend('topleft', c('Order 1','Order 2','Order 3','Order 4','Order 5'), lty=1, lwd=2, col=1:5, cex=1.2)


plot(density(pr[,1]), xlim=c(-0.5,1), ylim=c(0,5), main='pacf_residuals_ar1', xlab='Partial autocorrelation', cex.axis=1.3, cex.lab=1.4)
lines(density(pr[,2]), col=2)
lines(density(pr[,3]), col=3)
lines(density(pr[,4]), col=4)
lines(density(pr[,5]), col=5)
legend('topleft', c('Order 1','Order 2','Order 3','Order 4','Order 5'), lty=1, lwd=2, col=1:5, cex=1.2)
```

residual VS covariates in Model 2
 
```{R}
plot(x = fitted.values(fe_model2), y = residuals(fe_model2), main= "Model2: Fitted vs Residual")
lines(lowess(fitted.values(fe_model2), residuals(fe_model2)), col='red')


plot(x= mydf$T, y = residuals(fe_model2))
lines(lowess(mydf$T, residuals(fe_model2)), col='red')


plot(x= mydf$log_popdensi_sk, y = residuals(fe_model2))
lines(lowess(mydf$log_popdensi_sk, residuals(fe_model2)), col='red')


plot(x= mydf$weekly_cum_vaccinated, y = residuals(fe_model2))
lines(lowess(mydf$weekly_cum_vaccinated, residuals(fe_model2)), col='red')


plot(x= mydf$ContainmentHealthIndex1, y = residuals(fe_model2))
lines(lowess(mydf$ContainmentHealthIndex1, residuals(fe_model2)), col='red')
```

Put residuals into a matrix

```{R}
nn <- unique(mydf$County)
ncounty <- length(nn)
covid1 <- lapply(1:ncounty, function(i) mydf[mydf$County==nn[i], 'res'])
covid1 <- do.call(cbind, covid1)

dim(covid1)     #check: 99 counties, 97 observations (weeks) per county
```

Histogram and qqplot of residuals 

```{R}

hist(covid1, xlab = "residual of COVID", main = "hist of COVID residual", probability = TRUE)

qqnorm(covid1, main = "Q-Q Plot of COVID residual")
qqline(covid1, lwd = 3)

```

Save data

```{R}
#write.csv(SCI_index, file = paste("SCI_index", ".csv", sep = ""))
#write.csv(Geodist, file = paste("Geodist", ".csv", sep = ""))
#write.csv(covid1, file = paste("COVID", ".csv", sep = ""))
```



