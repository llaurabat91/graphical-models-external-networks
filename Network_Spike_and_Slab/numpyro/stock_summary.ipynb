{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eogcSYYbXHXX"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "from IPython.display import display_html \n",
    "import sys\n",
    "import os\n",
    "import jax\n",
    "import numpyro\n",
    "numpyro.set_platform('cpu')\n",
    "print(jax.lib.xla_bridge.get_backend().platform)\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "os.chdir(\"/Users/\")\n",
    "sys.path.append(\"functions\")\n",
    "\n",
    "data_save_path = './data/stock_market_data/'\n",
    "\n",
    "# load models and functions\n",
    "import models\n",
    "import my_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_vals = pd.read_csv(data_save_path + 'stock_trans.csv', index_col='Unnamed: 0').values\n",
    "E_clean = jnp.array(jnp.load(data_save_path + 'E_pears_clean.npy'))\n",
    "P_clean = jnp.array(jnp.load(data_save_path + 'P_pears_clean.npy'))\n",
    "net_no = 2\n",
    "\n",
    "n,p = stock_vals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1MCMC\n",
    "output_dict_glasso = { \"eta1_0\":[],\"Pos\":[], \"Neg\":[]}\n",
    "\n",
    "output_dict_ss_E_P = {\"eta0_0\":[],\"eta0_coefs\":[], \"eta1_0\":[],\"eta1_coefs\":[], \"eta2_0\":[],\"eta2_coefs\":[],\n",
    "                    \"w_slab\":[], \"mean_slab\":[], \"scale_slab\":[],\"Pos\":[], \"Neg\":[], \"Pos_95\":[], \"Neg_95\":[],}\n",
    "\n",
    "\n",
    "outputs = {\"GLASSO\":output_dict_glasso, \n",
    "           \"NetworkSS_E_P\":output_dict_ss_E_P }\n",
    "\n",
    "with open(data_save_path + f'glasso_mcmc.sav', 'rb') as fr:\n",
    "    res_glasso = pickle.load(fr)\n",
    "        \n",
    "with open(data_save_path + f'NetworkSS_E_P_1mcmc.sav', 'rb') as fr:\n",
    "    res_ss_E_P = pickle.load(fr)\n",
    "    \n",
    "\n",
    "all_res = {\"GLASSO\":res_glasso, \"NetworkSS_E_P\":res_ss_E_P}\n",
    "\n",
    "for i, res in all_res.items():\n",
    "    print(i)\n",
    "\n",
    "\n",
    "    outputs[i][\"eta1_0\"].append(res['all_samples'][\"eta1_0\"].mean(0))\n",
    "\n",
    "    try:\n",
    "        outputs[i][\"eta0_0\"].append(res['all_samples'][\"eta0_0\"].mean(0))\n",
    "        outputs[i][\"eta2_0\"].append(res['all_samples'][\"eta2_0\"].mean(0))\n",
    "        outputs[i][\"w_slab\"].append(res['all_samples'][\"w_slab\"].mean(0))\n",
    "        outputs[i][\"mean_slab\"].append(res['all_samples'][\"mean_slab\"].mean(0))\n",
    "        outputs[i][\"scale_slab\"].append(res['all_samples'][\"scale_slab\"].mean(0))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        outputs[i][\"eta1_coefs\"].append(res['all_samples'][\"eta1_coefs\"].mean(0))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:   \n",
    "        outputs[i][\"eta0_coefs\"].append(res['all_samples'][\"eta0_coefs\"].mean(0))\n",
    "        outputs[i][\"eta2_coefs\"].append(res['all_samples'][\"eta2_coefs\"].mean(0))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if 'eta0_0' not in outputs[i].keys():\n",
    "\n",
    "        outputs[i]['Pos'].append(res[\"Pos\"])\n",
    "        outputs[i]['Neg'].append(res[\"Neg\"])\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        outputs[i]['Pos'].append(res[\"Pos_5\"])\n",
    "        outputs[i]['Neg'].append(res[\"Neg_5\"])\n",
    "        outputs[i]['Pos_95'].append(res[\"Pos_95\"])\n",
    "        outputs[i]['Neg_95'].append(res[\"Neg_95\"])\n",
    "\n",
    "outputs_1MCMC = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2MCMC\n",
    "output_dict_glasso = {\"eta0_0\":[],\"eta1_0\":[],\"Pos\":[], \"Neg\":[]}\n",
    "\n",
    "\n",
    "output_dict_ss_E_P = {\"eta0_0\":[],\"eta0_coefs\":[], \"eta1_0\":[],\"eta1_coefs\":[], \"eta2_0\":[],\"eta2_coefs\":[],\n",
    "                    \"w_slab\":[], \"mean_slab\":[], \"scale_slab\":[],\"Pos\":[], \"Neg\":[], \"Pos_95\":[], \"Neg_95\":[],}\n",
    "\n",
    "\n",
    "outputs = {\"GLASSO\":output_dict_glasso, \n",
    "           \"NetworkSS_E_P\":output_dict_ss_E_P}\n",
    "\n",
    "with open(data_save_path +f'glasso_map.sav', 'rb') as fr:\n",
    "    svi_glasso = pickle.load(fr)\n",
    "\n",
    "with open(data_save_path +f'NetworkSS_E_P_2mcmc.sav', 'rb') as fr:\n",
    "    mcmc2_ss_E_P = pickle.load(fr)\n",
    "\n",
    "\n",
    "all_res_2MCMC = {\"GLASSO\":svi_glasso, \"NetworkSS_E_P\":mcmc2_ss_E_P}\n",
    "for i, res in all_res_2MCMC.items():\n",
    "    print(i)\n",
    "\n",
    "    try:\n",
    "\n",
    "        outputs[i]['Pos'].append(res[\"Pos\"])\n",
    "        outputs[i]['Neg'].append(res[\"Neg\"])\n",
    "\n",
    "\n",
    "    except:\n",
    "\n",
    "        outputs[i]['Pos'].append(res[\"Pos_5\"])\n",
    "        outputs[i]['Neg'].append(res[\"Neg_5\"])\n",
    "        outputs[i]['Pos_95'].append(res[\"Pos_95\"])\n",
    "        outputs[i]['Neg_95'].append(res[\"Neg_95\"])\n",
    "\n",
    "outputs_2MCMC = outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Pos', 'Neg', 'Pos_95', 'Neg_95']\n",
    "\n",
    "res_dict_1MCMC = {\"GLASSO\":[], \"NetworkSS_E_P\":[]}\n",
    "for k, output in outputs_1MCMC.items():\n",
    "    for col in cols:\n",
    "        try:\n",
    "            res_dict_1MCMC[k].append(round(jnp.array(output[col]).mean(0),3))\n",
    "        except:\n",
    "            res_dict_1MCMC[k].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Pos', 'Neg', 'Pos_95', 'Neg_95']\n",
    "\n",
    "res_dict_2MCMC = {\"GLASSO\":[],\"NetworkSS_E_P\":[]}\n",
    "for k, output in outputs_2MCMC.items():\n",
    "    for col in cols:\n",
    "        try:\n",
    "            res_dict_2MCMC[k].append(round(jnp.array(output[col]).mean(0),3))\n",
    "        except:\n",
    "            res_dict_2MCMC[k].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results for 1MCMC')\n",
    "pd.DataFrame.from_dict(res_dict_1MCMC, orient='index', \n",
    "                       columns=cols).loc[['GLASSO',  'NetworkSS_E_P']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results for 2MCMC')\n",
    "df = pd.DataFrame.from_dict(res_dict_2MCMC, orient='index', \n",
    "                       columns=cols).loc[['GLASSO', 'NetworkSS_E_P']]\n",
    "\n",
    "df.index = ['GLASSO_SVI', 'GOLAZO_SS_E_P_2mcmc']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkSS_E_P \n",
    "cols = [\"eta0_0\", \"eta1_0\",\"eta2_0\"]\n",
    "cols_2 = [ \"eta0_coefs\", \"eta1_coefs\", \"eta2_coefs\"]\n",
    "names = ['E', 'P']\n",
    "etas_NetworkSS = {}\n",
    "for k in cols:\n",
    "    etas_NetworkSS[k] = all_res_2MCMC['NetworkSS_E_P']['fixed_params_dict'][k]\n",
    "    \n",
    "for k in cols:\n",
    "    etas_NetworkSS[k] = {'MAP': all_res_2MCMC['NetworkSS_E_P']['fixed_params_dict'][k],\n",
    "               'mean': all_res['NetworkSS_E_P']['all_samples'][k].mean(0),\n",
    "              'ESS': numpyro.diagnostics.summary(jnp.expand_dims(all_res['NetworkSS_E_P']['all_samples'][k],0))['Param:0']['n_eff'],\n",
    "               'r_hat': numpyro.diagnostics.summary(jnp.expand_dims(all_res['NetworkSS_E_P']['all_samples'][k],0))['Param:0']['r_hat'],\n",
    "                }\n",
    "\n",
    "for k in cols_2:\n",
    "    for net_ix in range(net_no):\n",
    "        etas_NetworkSS[f'{k}_{names[net_ix]}'] = {'MAP': all_res_2MCMC['NetworkSS_E_P']['fixed_params_dict'][k][net_ix],\n",
    "                   'mean': all_res['NetworkSS_E_P']['all_samples'][k].mean(0)[net_ix],\n",
    "                  'ESS': numpyro.diagnostics.summary(jnp.expand_dims(all_res['NetworkSS_E_P']['all_samples'][k][:,net_ix].flatten(),0))['Param:0']['n_eff'],\n",
    "                   'r_hat': numpyro.diagnostics.summary(jnp.expand_dims(all_res['NetworkSS_E_P']['all_samples'][k][:,net_ix].flatten(),0))['Param:0']['r_hat'],\n",
    "                    }\n",
    "        \n",
    "df_NetworkSS_etas_spec = pd.DataFrame.from_dict(etas_NetworkSS, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NetworkSS_etas_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tril_idx = jnp.tril_indices(n=p, k=-1, m=p)\n",
    "A_tril_E = E_clean[tril_idx]\n",
    "A_tril_P = P_clean[tril_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetworkSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params_MAP_dict = all_res_2MCMC['NetworkSS_E_P']['fixed_params_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_fixed_params_MAP_dict = {k:(-v if 'eta0' in k else v) \n",
    "                              for k,v in fixed_params_MAP_dict.items()\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas_dict = negative_fixed_params_MAP_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_E_ints_10, A_E_mids_10  = my_utils.get_density_els_marginal(A_tril=A_tril_E, \n",
    "                                                                  A_tril_pos=0, \n",
    "                                                                len_A_list=2, nbins=nbins, \n",
    "                         eta_dict=etas_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_P_ints_10, A_P_mids_10 = my_utils.get_density_els_marginal(A_tril=A_tril_P, \n",
    "                                                                 A_tril_pos=1, \n",
    "                                                                len_A_list=2, nbins=nbins, \n",
    "                         eta_dict=etas_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credible_interval(post_chain):\n",
    "    # Credible Intervals\n",
    "    sorted_arr = np.sort(post_chain) # for each K sort chain\n",
    "    len_sample = post_chain.shape[0] # len chain\n",
    "\n",
    "    # 2.5% percentile: if integer pick value, else average of values at pos5 and pos5+1, recall python idx at 0 (lower bound)\n",
    "    pos025 = 0.025*len_sample\n",
    "    if pos025 == np.int(pos025):\n",
    "        lb025 = sorted_arr[max(np.int(pos025)-1,0)]\n",
    "    else:\n",
    "        lb025 = (sorted_arr[max(np.int(pos025)-1,0)] + sorted_arr[np.int(pos025)])/2\n",
    "\n",
    "    # 97.5% percentile: if integer pick value, else average of values at pos95 and pos95+1, recall python idx at 0 (upper bound)\n",
    "    pos975 = 0.975*len_sample\n",
    "    if pos975 == np.int(pos975):\n",
    "        ub975 = sorted_arr[np.int(pos975)-1]\n",
    "    else:\n",
    "        ub975 = (sorted_arr[(np.int(pos975)-1)] + sorted_arr[np.int(pos975)])/2\n",
    "        \n",
    "    return (jnp.round(lb025,3), jnp.round(ub975,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MAP_dict = {'intercept':{'eta0_m':jnp.round(df_NetworkSS_etas_spec['MAP']['eta0_0'],3),\n",
    "                        'eta0_CI':get_credible_interval(res_ss_E_P['all_samples']['eta0_0']),\n",
    "                        'eta1_m':jnp.round(df_NetworkSS_etas_spec['MAP']['eta1_0'],3),\n",
    "                        'eta1_CI':get_credible_interval(res_ss_E_P['all_samples']['eta1_0']),\n",
    "                        'eta2_m':jnp.round(df_NetworkSS_etas_spec['MAP']['eta2_0'],3),\n",
    "                        'eta2_CI':get_credible_interval(res_ss_E_P['all_samples']['eta2_0']),},\n",
    "               \n",
    "'E':{'eta0_m':jnp.round(df_NetworkSS_etas_spec['MAP']['eta0_coefs_E'],3),\n",
    "                        'eta0_CI':get_credible_interval(res_ss_E_P['all_samples']['eta0_coefs'][:,0]),\n",
    "                        'eta1_m':jnp.round(df_NetworkSS_etas_spec['MAP']['eta1_coefs_E'],3),\n",
    "                        'eta1_CI':get_credible_interval(res_ss_E_P['all_samples']['eta1_coefs'][:,0]),\n",
    "                        'eta2_m':jnp.round(df_NetworkSS_etas_spec['MAP']['eta2_coefs_E'],3),\n",
    "                        'eta2_CI':get_credible_interval(res_ss_E_P['all_samples']['eta2_coefs'][:,0]),},\n",
    "\n",
    "'P':{'eta0_m':jnp.round(df_NetworkSS_etas_spec['MAP']['eta0_coefs_P'],3),\n",
    "                        'eta0_CI':get_credible_interval(res_ss_E_P['all_samples']['eta0_coefs'][:,1]),\n",
    "                        'eta1_m':jnp.round(df_NetworkSS_etas_spec['MAP']['eta1_coefs_P'],3),\n",
    "                        'eta1_CI':get_credible_interval(res_ss_E_P['all_samples']['eta1_coefs'][:,1]),\n",
    "                        'eta2_m':jnp.round(df_NetworkSS_etas_spec['MAP']['eta2_coefs_P'],3),\n",
    "                        'eta2_CI':get_credible_interval(res_ss_E_P['all_samples']['eta2_coefs'][:,1]),},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(df_MAP_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(df_MAP_dict).to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MODIFIED_get_density_els_marginal(A_tril, A_min, A_max, A_tril_pos, len_A_list, nbins, eta_dict):\n",
    "    bins = np.histogram(A_tril, bins=nbins)[1]\n",
    "    delta = jnp.diff(np.histogram(A_tril, bins=nbins)[1])[0]\n",
    "    if min(bins) > A_min:\n",
    "        low = bins[0]\n",
    "        while low>A_min:\n",
    "            low -= delta\n",
    "            bins = jnp.concatenate([jnp.array([low]), bins])\n",
    "    if max(bins) < A_max:\n",
    "        high = bins[-1]\n",
    "        while high<A_max:\n",
    "            high += delta\n",
    "            bins = jnp.concatenate([bins, jnp.array([high])])\n",
    "\n",
    "    A_ints = {}\n",
    "    A_mids = []\n",
    "    down = -jnp.inf\n",
    "    for i in range(-1, len(bins)-2):\n",
    "        up = bins[i+2]\n",
    "        if i==-1:\n",
    "            A_mid = up-(bins[i+3]-bins[i+2])/2\n",
    "            A_mids.append(A_mid)\n",
    "        else:\n",
    "            A_mid = (down+up)/2\n",
    "            A_mids.append(A_mid)\n",
    "        A_int_ix = jnp.where((A_tril>down)&(A_tril<=up))[0]\n",
    "\n",
    "        A_key = f'{jnp.round(down,2)} to {jnp.round(up,2)}'\n",
    "        down = bins[i+2]\n",
    "\n",
    "        zeros = jnp.zeros((len_A_list))\n",
    "        A_singlevals = zeros.at[A_tril_pos].set(A_mid)\n",
    "\n",
    "        par_dict = my_utils.from_etas_to_params(coef_dict=eta_dict, p=1, \n",
    "        model='golazo_ss', A_list=A_singlevals)\n",
    "\n",
    "        A_ints[A_key] = par_dict\n",
    "\n",
    "    A_mids = jnp.array(A_mids)\n",
    "    return A_ints, A_mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to have plots in LaTeX format\n",
    "\n",
    "params = {'font.family': 'serif',\n",
    "          'text.usetex': True,\n",
    "          'axes.titlesize': 13,\n",
    "          'axes.labelsize': 13,\n",
    "          'xtick.labelsize': 13,\n",
    "          'ytick.labelsize': 13,\n",
    "          'legend.fontsize': 9,\n",
    "          'font.weight': 'bold'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( figsize=(5,4))\n",
    "\n",
    "nbins=10\n",
    "MODIFIED_A_E_ints_10, MODIFIED_A_E_mids_10  = MODIFIED_get_density_els_marginal(A_tril=A_tril_E, \n",
    "                                                                  A_min=-2, A_max=6.5, \n",
    "                                                                  A_tril_pos=0, \n",
    "                                                                len_A_list=2, nbins=nbins,  eta_dict=etas_dict)\n",
    "\n",
    "MODIFIED_A_P_ints_10, MODIFIED_A_P_mids_10 = MODIFIED_get_density_els_marginal(A_tril=A_tril_P, \n",
    "                                                                                   A_min=-2, A_max=6.5,\n",
    "                                                                 A_tril_pos=1, \n",
    "                                                                len_A_list=2, nbins=nbins, eta_dict=etas_dict)\n",
    "\n",
    "\n",
    "MODIFIED_df = pd.DataFrame.from_dict(MODIFIED_A_P_ints_10, orient='index')\n",
    "MODIFIED_df = MODIFIED_df.astype('float64')\n",
    "MODIFIED_df_P = MODIFIED_df.round(decimals = 5)\n",
    "\n",
    "MODIFIED_df = pd.DataFrame.from_dict(MODIFIED_A_E_ints_10, orient='index')\n",
    "MODIFIED_df = MODIFIED_df.astype('float64')\n",
    "MODIFIED_df_E = MODIFIED_df.round(decimals = 5)\n",
    "\n",
    "dfs = [MODIFIED_df_P, MODIFIED_df_E, ]\n",
    "df_names = ['P', 'E', ]\n",
    "ticklabs = [MODIFIED_A_P_mids_10, MODIFIED_A_E_mids_10 ]\n",
    "legendlabs = ['Policy Connectivity Index', 'Economic Distance Network', ]\n",
    "colors = ['black', 'gray']\n",
    "\n",
    "\n",
    "for df_ix, df in enumerate(dfs):\n",
    "    ax.plot(ticklabs[df_ix], df['w_slab'].values, linewidth=1.2, label=legendlabs[df_ix], color=colors[df_ix])\n",
    "\n",
    "    ax.set_ylabel('Probability of slab')\n",
    "    ax.set_xlabel('Network values')\n",
    "\n",
    "plt.legend()\n",
    "plt.yticks(rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Stock_SS_prob_slab.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( figsize=(5,4))\n",
    "\n",
    "MODIFIED_A_E_ints_10, MODIFIED_A_E_mids_10  = MODIFIED_get_density_els_marginal(A_tril=A_tril_E, \n",
    "                                                                  A_min=-2, A_max=6.5, \n",
    "                                                                  A_tril_pos=0, \n",
    "                                                                len_A_list=2, nbins=nbins,  eta_dict=etas_dict)\n",
    "\n",
    "MODIFIED_A_P_ints_10, MODIFIED_A_P_mids_10 = MODIFIED_get_density_els_marginal(A_tril=A_tril_P, \n",
    "                                                                                   A_min=-2, A_max=6.5,\n",
    "                                                                 A_tril_pos=1, \n",
    "                                                                len_A_list=2, nbins=nbins, eta_dict=etas_dict)\n",
    "\n",
    "\n",
    "MODIFIED_df = pd.DataFrame.from_dict(MODIFIED_A_P_ints_10, orient='index')\n",
    "MODIFIED_df = MODIFIED_df.astype('float64')\n",
    "MODIFIED_df_P = MODIFIED_df.round(decimals = 5)\n",
    "\n",
    "MODIFIED_df = pd.DataFrame.from_dict(MODIFIED_A_E_ints_10, orient='index')\n",
    "MODIFIED_df = MODIFIED_df.astype('float64')\n",
    "MODIFIED_df_E = MODIFIED_df.round(decimals = 5)\n",
    "\n",
    "dfs = [MODIFIED_df_P, MODIFIED_df_E, ]\n",
    "df_names = ['P', 'E', ]\n",
    "ticklabs = [MODIFIED_A_P_mids_10, MODIFIED_A_E_mids_10 ]\n",
    "legendlabs = ['Policy Connectivity Index', 'Economic Distance Network', ]\n",
    "colors = ['black', 'gray']\n",
    "\n",
    "\n",
    "for df_ix, df in enumerate(dfs):\n",
    "    ax.plot(ticklabs[df_ix], df['mean_slab'].values, linewidth=1.2, label=legendlabs[df_ix], color=colors[df_ix])\n",
    "\n",
    "    ax.set_ylabel('Slab location')\n",
    "    ax.set_xlabel('Network values')\n",
    "\n",
    "plt.legend()\n",
    "plt.yticks(rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Stock_SS_mean_slab.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "\n",
    "with open(data_save_path +f'glasso_map.sav', 'rb') as fr:\n",
    "    svi_glasso = pickle.load(fr)\n",
    "\n",
    "with open(data_save_path +f'NetworkSS_E_P_2mcmc.sav', 'rb') as fr:\n",
    "    mcmc2_ss_E_P = pickle.load(fr)\n",
    "    \n",
    "x_axis = jnp.arange(-1,1,0.001)\n",
    "rho_tril_GLASSO = svi_glasso['rho_lt']\n",
    "rho_tril = mcmc2_ss_E_P['all_samples']['rho_lt'].mean(0)\n",
    "\n",
    "densities_E_P_P = []\n",
    "for A_ix, (A_k, vals) in enumerate(A_P_ints_10.items()):\n",
    "    density = jnp.exp(jnp.array([models.logprior_NetworkSS(scale_spike=vals['scale_spike'],\n",
    "                                                           scale_slab=vals['scale_slab'],\n",
    "                                                           w_slab=vals['w_slab'],\n",
    "                                                           mean_slab=vals['mean_slab'],\n",
    "                                                           rho_lt=x) for x in x_axis]))\n",
    "    densities_E_P_P.append(density)\n",
    "    ax.plot(density+A_P_mids_10[A_ix], x_axis, alpha=0.3, c='gray')\n",
    "    \n",
    "ax.scatter(A_tril_P, -rho_tril, s=18, linewidth=0.8, alpha=0.7, color='black', facecolors='none', label='partial correlations')\n",
    "ax.set_xlim(-3,14)\n",
    "ax.set_ylim(-0.5, 0.7)\n",
    "ax.set_xlabel('Policy Connectivity Index')\n",
    "ax.set_ylabel('Partial correlation (Network-SS)')\n",
    "\n",
    "plt.yticks(rotation = 90) \n",
    "plt.tight_layout()\n",
    "plt.savefig('Stock_SS_partial_corrs_P.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "\n",
    "with open(data_save_path +f'glasso_map.sav', 'rb') as fr:\n",
    "    svi_glasso = pickle.load(fr)\n",
    "\n",
    "with open(data_save_path +f'NetworkSS_E_P_2mcmc.sav', 'rb') as fr:\n",
    "    mcmc2_ss_E_P = pickle.load(fr)\n",
    "    \n",
    "x_axis = jnp.arange(-1,1,0.001)\n",
    "rho_tril_GLASSO = svi_glasso['rho_lt']\n",
    "rho_tril = mcmc2_ss_E_P['all_samples']['rho_lt'].mean(0)\n",
    "\n",
    "densities_E_P_E = []\n",
    "for A_ix, (A_k, vals) in enumerate(A_E_ints_10.items()):\n",
    "    density = jnp.exp(jnp.array([models.logprior_NetworkSS(scale_spike=vals['scale_spike'],\n",
    "                                                           scale_slab=vals['scale_slab'],\n",
    "                                                           w_slab=vals['w_slab'],\n",
    "                                                           mean_slab=vals['mean_slab'],\n",
    "                                                           rho_lt=x) for x in x_axis]))\n",
    "    densities_E_P_E.append(density)\n",
    "    ax.plot(density+A_E_mids_10[A_ix], x_axis, alpha=0.3, c='gray')\n",
    "    \n",
    "ax.scatter(A_tril_E, -rho_tril, s=18, linewidth=0.8, alpha=0.7, color='black', facecolors='none', label='partial correlations')\n",
    "ax.set_xlim(-3,14)\n",
    "ax.set_ylim(-0.5, 0.7)\n",
    "ax.set_xlabel('Economic Distance Network')\n",
    "ax.set_ylabel('Partial correlation (Network-SS)')\n",
    "\n",
    "plt.yticks(rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Stock_SS_partial_corrs_E.pdf')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
